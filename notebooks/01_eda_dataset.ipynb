{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA: Exploring the Frankenstein Dataset\n",
        "\n",
        "## Why EDA Matters for Language Model Training\n",
        "\n",
        "Before training, we need to understand our data:\n",
        "- **Length distribution:** Are texts too short/long? This affects tokenization and memory.\n",
        "- **Duplicates:** Duplicate samples can cause overfitting and inflate metrics.\n",
        "- **Encoding issues:** Non-ASCII characters, special symbols, or encoding errors can break tokenization.\n",
        "- **Noise:** Empty strings, placeholder text, or corrupted entries waste compute.\n",
        "\n",
        "For language models, data quality directly impacts:\n",
        "- Training stability (bad data → NaN losses)\n",
        "- Generalization (duplicates → memorization)\n",
        "- Memory usage (long sequences → OOM errors)\n",
        "\n",
        "## Goals\n",
        "\n",
        "1. Load and inspect the CSV structure\n",
        "2. Analyze text length distributions\n",
        "3. Identify and clean obvious issues\n",
        "4. Prepare a clean dataset for tokenization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Load CSV into a DataFrame; assert 'text' column exists and non-empty.\n",
        "# Hints:\n",
        "#   - Use pandas.read_csv()\n",
        "#   - Check for 'text' column with assert or if statement\n",
        "#   - Count missing values and duplicates\n",
        "# Acceptance:\n",
        "#   - prints n_rows, n_missing, n_dupes\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def load_snippets(csv_path):\n",
        "    \"\"\"\n",
        "    Load CSV file and validate structure.\n",
        "    \n",
        "    Args:\n",
        "        csv_path: Path to CSV file with 'text' column\n",
        "        \n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with 'text' column\n",
        "    \"\"\"\n",
        "    raise NotImplementedError\n",
        "\n",
        "# Load and inspect\n",
        "df = load_snippets(\"data/raw/frankenstein_chunks.csv\")\n",
        "print(f\"Loaded {len(df)} rows\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Length Analysis\n",
        "\n",
        "Text length matters for language models:\n",
        "- **Too short:** Wastes padding tokens, less context\n",
        "- **Too long:** Exceeds model's max sequence length, gets truncated\n",
        "\n",
        "We'll plot distributions in both characters and approximate tokens (whitespace-split for EDA).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Plot length histogram in tokens (roughly) and characters.\n",
        "# Hints:\n",
        "#   - Simple whitespace token counts are fine for EDA\n",
        "#   - Use matplotlib or seaborn for histograms\n",
        "#   - Show both character and token distributions\n",
        "# Acceptance:\n",
        "#   - displays two plots\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_lengths(df):\n",
        "    \"\"\"\n",
        "    Plot text length distributions (characters and approximate tokens).\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame with 'text' column\n",
        "    \"\"\"\n",
        "    raise NotImplementedError\n",
        "\n",
        "plot_lengths(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleaning\n",
        "\n",
        "Minimal cleaning for language model training:\n",
        "- Strip leading/trailing whitespace\n",
        "- Drop empty strings\n",
        "- Remove duplicates\n",
        "- Normalize quotes (optional, but helps consistency)\n",
        "\n",
        "We keep cleaning minimal to preserve the original style.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Clean minimal issues: strip whitespace, drop empties/dupes, normalize quotes.\n",
        "# Hints:\n",
        "#   - Use .str.strip() for whitespace\n",
        "#   - Drop rows where text is empty after stripping\n",
        "#   - Use .drop_duplicates() on 'text' column\n",
        "#   - Optionally normalize quotes (smart quotes → straight quotes)\n",
        "# Acceptance:\n",
        "#   - returns cleaned DataFrame with a 'text' col\n",
        "#   - prints before/after row counts\n",
        "\n",
        "def clean_snippets(df):\n",
        "    \"\"\"\n",
        "    Clean text snippets for language model training.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame with 'text' column\n",
        "        \n",
        "    Returns:\n",
        "        pd.DataFrame: Cleaned DataFrame\n",
        "    \"\"\"\n",
        "    raise NotImplementedError\n",
        "\n",
        "df_clean = clean_snippets(df)\n",
        "print(f\"Cleaned: {len(df)} → {len(df_clean)} rows\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Cleaned Data\n",
        "\n",
        "Save the cleaned dataset for the next step.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save cleaned data\n",
        "df_clean.to_csv(\"data/processed/frankenstein_cleaned.csv\", index=False)\n",
        "print(\"Cleaned data saved!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
